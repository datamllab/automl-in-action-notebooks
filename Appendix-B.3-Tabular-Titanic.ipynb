{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "!pip install -r https://raw.githubusercontent.com/datamllab/automl-in-action-notebooks/master/requirements.txt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Load data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "# Import the dataset loading function from sklearn\n",
    "from sklearn.datasets import fetch_openml\n",
    "\n",
    "# Load the titanic dataset from openml\n",
    "titanic = fetch_openml(name=\"titanic\", version=1, as_frame=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "data, label = titanic.data.copy(), titanic.target.copy()\n",
    "data.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "data.dtypes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "# look at the data\n",
    "print(\"\\n-- | Shape of the data -> (n_sample * n_feature) |--\\n {}\".format(data.shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "label\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Feature engineering: deal with missing values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "data.isnull().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "print(\"-- # missing values --\\n{}\".format(data.isnull().sum()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Simple drop out the features with too many missing values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "# Remove 'cabin', 'boat', 'body' features\n",
    "data = data.drop([\"cabin\", \"boat\", \"body\", \"home.dest\"], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "data.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Imputation missing fare and embarked with sensible feature correlation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "boxplot = sns.boxplot(x=\"embarked\", y=\"fare\", data=data, hue=\"pclass\")\n",
    "boxplot.axhline(80)\n",
    "boxplot.set_title(\"Boxplot of fare grouped by embarked and pclass\")\n",
    "boxplot.text(x=2.6, y=80, s=\"fare = $80\", size=\"medium\", color=\"blue\", weight=\"bold\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "data[data[\"embarked\"].isnull()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "# Impute missing value in embarked\n",
    "data[\"embarked\"][[168, 284]] = \"C\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "data[data[\"fare\"].isnull()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "# Impute missing value in fare\n",
    "data[\"fare\"][1225] = (\n",
    "    data.groupby([\"embarked\", \"pclass\"]).get_group((\"S\", 3))[\"fare\"].median()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Imputation missing age with naive statistical information\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "# Use median age to fill the missing ages\n",
    "data[\"age\"].fillna(data[\"age\"].median(skipna=True), inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "##### NOTE: We could also use sensible value information such as the relationship betwee\n",
    "embarked and fare predictive relationship to fill the missing values of the age variable\n",
    "rather than directly use statistical median. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "print(\"\\n-- # of missing values --\\n{}\".format(data.isnull().sum()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Feature engineering: name title extraction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "data[\"title\"] = data[\"name\"].str.extract(\" ([A-Za-z]+)\\.\", expand=False)\n",
    "data[\"title\"].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "data[\"title\"] = data[\"title\"].replace(\n",
    "    [\n",
    "        \"Lady\",\n",
    "        \"Countess\",\n",
    "        \"Capt\",\n",
    "        \"Col\",\n",
    "        \"Don\",\n",
    "        \"Dr\",\n",
    "        \"Major\",\n",
    "        \"Rev\",\n",
    "        \"Sir\",\n",
    "        \"Jonkheer\",\n",
    "        \"Dona\",\n",
    "    ],\n",
    "    \"Rare\",\n",
    ")\n",
    "data[\"title\"] = data[\"title\"].replace(\"Mlle\", \"Miss\")\n",
    "data[\"title\"] = data[\"title\"].replace(\"Ms\", \"Miss\")\n",
    "data[\"title\"] = data[\"title\"].replace(\"Mme\", \"Mrs\")\n",
    "\n",
    "data = data.drop([\"name\"], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "data.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Feature engineering: categorical feature enoding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "data[\"ticket\"].describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "encode_col_list = [\"sex\", \"embarked\", \"title\"]\n",
    "for i in encode_col_list:\n",
    "    data = pd.concat([data, pd.get_dummies(data[i], prefix=i)], axis=1)\n",
    "    data.drop(i, axis=1, inplace=True)\n",
    "\n",
    "# direct drop the ticket feature here since it is a categorical feature with too high\n",
    "levels\n",
    "data[\"ticket\"].describe()\n",
    "data.drop(\"ticket\", axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "data.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "data.dtypes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Split Training / Testing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### NOTE: Here we do feature engineering first and then do the split.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "# Split data into training and test dataset\n",
    "X_train, X_test, y_train, y_test = data[:891], data[891:], label[:891], label[891:]\n",
    "\n",
    "print(\"--Shape of the training data--\\n {}\".format(X_train.shape))\n",
    "print(\"\\n--Shape of the testing data--\\n {}\".format(X_test.shape))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Build up a Decision Tree, a Random Forest & a GBDT classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, plot_confusion_matrix\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### decision tree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dt_clf = DecisionTreeClassifier(criterion=\"entropy\", random_state=42)\n",
    "dt_clf.fit(X_train, y_train)\n",
    "\n",
    "# Now predict the value of the digit on the test set:\n",
    "y_pred_test = dt_clf.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "# Display the testing results\n",
    "acc = accuracy_score(y_test, y_pred_test)\n",
    "print(\"Test accuracy: {:.2f} %\".format(acc * 100))\n",
    "\n",
    "disp = plot_confusion_matrix(dt_clf, X_test, y_test)\n",
    "disp.figure_.suptitle(\"Confusion Matrix of DT CLF\")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "\n",
    "# Train and test Random Forest\n",
    "rf_clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_clf.fit(X_train, y_train)\n",
    "y_pred_test = rf_clf.predict(X_test)\n",
    "acc_rf = accuracy_score(y_test, y_pred_test)\n",
    "\n",
    "# Train and test GBDT\n",
    "gbdt_clf = GradientBoostingClassifier(n_estimators=100, random_state=42)\n",
    "gbdt_clf.fit(X_train, y_train)\n",
    "y_pred_test = gbdt_clf.predict(X_test)\n",
    "acc_gbdt = accuracy_score(y_test, y_pred_test)\n",
    "\n",
    "# Pring the results\n",
    "print(\"Random forest test accuracy: {:.2f} %\".format(acc_rf * 100))\n",
    "print(\"GBDT test accuracy: {:.2f} %\".format(acc_gbdt * 100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "disp = plot_confusion_matrix(rf_clf, X_test, y_test)\n",
    "disp.figure_.suptitle(\"Confusion Matrix of RF CLF\")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "disp = plot_confusion_matrix(gbdt_clf, X_test, y_test)\n",
    "disp.figure_.suptitle(\"Confusion Matrix of GBDT CLF\")\n",
    "\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Appendix-B.3-Tabular-Titanic",
   "private_outputs": false,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}