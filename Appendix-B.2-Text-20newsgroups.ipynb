{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "!pip install -r https://raw.githubusercontent.com/datamllab/automl-in-action-notebooks/master/requirements.txt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Load data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "news_train = fetch_20newsgroups(subset=\"train\", shuffle=True, random_state=42)\n",
    "news_test = fetch_20newsgroups(subset=\"test\", shuffle=True, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Exploratory data analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "doc_train, label_train = news_train.data, news_train.target\n",
    "doc_test, label_test = news_test.data, news_test.target\n",
    "\n",
    "print(\"The number of documents for training: {}.\".format(len(doc_train)))\n",
    "print(\"The number of documents for testing: {}.\\n\".format(len(doc_test)))\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "print(\n",
    "    \"Unique labels {}. \\nNumber of unique labels: {}.\\n\\n\".format(\n",
    "        np.unique(label_train), len(np.unique(label_train))\n",
    "    )\n",
    ")\n",
    "\n",
    "print(type(doc_train[0]))\n",
    "print(\"\\nThe first training document:\\n\\n{}\".format(doc_train[0]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Data preprocessing &  feature engineering\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "# Tokenization\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "count_vec = CountVectorizer()\n",
    "X_train_counts = count_vec.fit_transform(doc_train)\n",
    "X_train_counts.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "# TF-IDF\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "X_train_tfidf.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Build up a logistic regression classfier & a Naive Bayes classifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### logistic regression classfier \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "# Train\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr_clf = LogisticRegression(multi_class=\"ovr\", random_state=42)\n",
    "lr_clf.fit(X_train_tfidf, label_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "# Test\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "X_test_counts = count_vec.transform(doc_test)\n",
    "X_test_tfidf = tfidf_transformer.transform(X_test_counts)\n",
    "label_pred_test = lr_clf.predict(X_test_tfidf)\n",
    "\n",
    "lr_acc = accuracy_score(label_test, label_pred_test)\n",
    "print(\"Test accuracy: {:.2f} %\".format(lr_acc * 100))\n",
    "\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "\n",
    "# Display the testing results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "disp = plot_confusion_matrix(lr_clf, X_test_tfidf, label_test)\n",
    "disp.figure_.suptitle(\"Confusion Matrix\")\n",
    "disp.figure_.set_size_inches(20, 10)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Naive Bayes classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "# Train\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "nb_clf = MultinomialNB().fit(X_train_tfidf, label_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "# Test\n",
    "X_test_counts = count_vec.transform(doc_test)\n",
    "X_test_tfidf = tfidf_transformer.transform(X_test_counts)\n",
    "label_pred_test = nb_clf.predict(X_test_tfidf)\n",
    "\n",
    "lr_acc = accuracy_score(label_test, label_pred_test)\n",
    "print(\"Test accuracy: {:.2f} %\".format(lr_acc * 100))\n",
    "\n",
    "# Display the testing results\n",
    "disp = plot_confusion_matrix(nb_clf, X_test_tfidf, label_test)\n",
    "disp.figure_.suptitle(\"Confusion Matrix\")\n",
    "disp.figure_.set_size_inches(20, 10)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Build a pipeline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Fine-Tuning: jointly tune three hyperparameters of the whole pipepline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "# Build up the decision tree regressor\n",
    "text_clf = Pipeline(\n",
    "    [\n",
    "        (\"vect\", CountVectorizer()),\n",
    "        (\"tfidf\", TfidfTransformer()),\n",
    "        (\"clf\", MultinomialNB()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Create a dictionary for all the hyperparameters\n",
    "hps = {\n",
    "    \"vect__ngram_range\": [(1, 1), (1, 2)],\n",
    "    \"tfidf__use_idf\": (True, False),\n",
    "    \"clf__alpha\": (1, 1e-1, 1e-2),\n",
    "}\n",
    "\n",
    "# Transform the performance_metric into a scoring function using 'make_scorer'.\n",
    "scoring_fnc = make_scorer(accuracy_score)\n",
    "\n",
    "# Create the grid search cv object (3-fold cross-validation)\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=text_clf, param_grid=hps, scoring=scoring_fnc, cv=3, verbose=5, n_jobs=-1\n",
    ")\n",
    "\n",
    "# Fit the grid search object to the training data to search the optimal model\n",
    "grid_search = grid_search.fit(doc_train, label_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "cvres = grid_search.cv_results_\n",
    "for mean_score, params in zip(cvres[\"mean_test_score\"], cvres[\"params\"]):\n",
    "    print(mean_score, params)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Retrive the best model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "grid_search.best_params_\n",
    "best_pipeline = grid_search.best_estimator_\n",
    "\n",
    "# Produce the value for 'max_depth'\n",
    "print(\"The best combination of hyperparameters are:\")\n",
    "\n",
    "for hp_name in sorted(hps.keys()):\n",
    "    print(\"%s: %r\" % (hp_name, grid_search.best_params_[hp_name]))\n",
    "\n",
    "best_pipeline.fit(doc_train, label_train)\n",
    "\n",
    "# Model prediction on training & test data\n",
    "label_pred_train = best_pipeline.predict(doc_train)\n",
    "label_pred_test = best_pipeline.predict(doc_test)\n",
    "\n",
    "# Display the testing results\n",
    "train_acc = accuracy_score(label_train, label_pred_train)\n",
    "test_acc = accuracy_score(label_test, label_pred_test)\n",
    "print(\"\\nThe prediction accuracy on training set: {:.2f} %\".format(train_acc * 100))\n",
    "print(\"The prediction accuracy on test set: {:.2f} %\".format(test_acc * 100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "train_acc = accuracy_score(label_train, label_pred_train)\n",
    "test_acc = accuracy_score(label_test, label_pred_test)\n",
    "print(\"Training Accuracy: {:.2f} %\".format(train_acc * 100))\n",
    "print(\"Test Accuracy: {:.2f} %\".format(test_acc * 100))\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Appendix-B.2-Text-20newsgroups",
   "private_outputs": false,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}