{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "!pip install -r https://raw.githubusercontent.com/datamllab/automl-in-action-notebooks/master/requirements.txt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Load data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "# Import the dataset loading function from sklearn\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "\n",
    "# Load the California housing dataset\n",
    "house_dataset = fetch_california_housing()\n",
    "\n",
    "# Display the oringal data\n",
    "house_dataset.keys()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "# Import pandas package to format the data\n",
    "import pandas as pd\n",
    "\n",
    "# Extract features with their names into the a dataframe format\n",
    "data = pd.DataFrame(house_dataset.data, columns=house_dataset.feature_names)\n",
    "\n",
    "# Extract target with their names into a pd.Series object with name MedPrice\n",
    "target = pd.Series(house_dataset.target, name=\"MedPrice\")\n",
    "\n",
    "# Visualize the first 5 samples of the data\n",
    "data.head(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Split the dataset into training and test set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "# Split data into training and test dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data, target, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Check the shape of whole dataset and the splited training and test set\n",
    "print(\"--Shape of the whole data--\\n {}\".format(data.shape))\n",
    "print(\"\\n--Shape of the target vector--\\n {}\".format(target.shape))\n",
    "print(\"\\n--Shape of the training data--\\n {}\".format(X_train.shape))\n",
    "print(\"\\n--Shape of the testing data--\\n {}\".format(X_test.shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "(data.shape, target.shape), (X_train.shape, y_train.shape), (X_test.shape, y_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Exploratory data analysis  &  data preprocessing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Q1: What are the data type of the values in each feature?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "data.dtypes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "# Check for feature value type\n",
    "print(\"-- Feature type --\\n{}\".format(data.dtypes))\n",
    "print(\"\\n-- Target type --\\n{}\".format(target.dtypes))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Q2: How many distinct values each feature has in the dataset?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "# Check for unique feature values\n",
    "print(\"\\n-- # of unique feature values --\\n{}\".format(data.nunique()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Q3: What are the scale and basic statistics of each feature?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "# Viewing the data statistics\n",
    "pd.options.display.float_format = \"{:,.2f}\".format\n",
    "data.describe()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Q4: Are there missing values contained in the data?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "# Copy data to avoid inplace\n",
    "train_data = X_train.copy()\n",
    "\n",
    "# Add a column \"MedPrice\" for the target house price\n",
    "train_data[\"MedPrice\"] = y_train\n",
    "\n",
    "# Check if there're missing values\n",
    "print(\n",
    "    \"\\n-- check missing values in training data --\\n{}\".format(\n",
    "        train_data.isnull().any()\n",
    "    )\n",
    ")\n",
    "print(\"\\n-- check missing values in test data --\\n{}\".format(X_test.isnull().any()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "##   Feature engineering: feature selection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "# Can we gain some insights by visualizing the distribution of them or correlationship between them?\n",
    "# Import libraries for plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "# Pretty display for notebooks (only in a Jupyter notebook)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Plot the correlation across all the features and the target\n",
    "plt.figure(figsize=(30, 10))\n",
    "\n",
    "correlation_matrix = train_data.corr().round(2)\n",
    "sns.heatmap(\n",
    "    data=correlation_matrix, square=True, annot=True, cmap=\"Blues\"\n",
    ")  # fmt='.1f', annot_kws={'size':15},\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "# Select high correlation features & display the pairplot\n",
    "\n",
    "selected_feature_set = [\"MedInc\", \"AveRooms\"]  # 'PTRATIO', , 'Latitude', 'HouseAge'\n",
    "sub_train_data = train_data[selected_feature_set + [\"MedPrice\"]]\n",
    "\n",
    "# Extract the new training features\n",
    "X_train = sub_train_data.drop([\"MedPrice\"], axis=1)\n",
    "\n",
    "# Select same feature sets for test data\n",
    "X_test = X_test[selected_feature_set]\n",
    "\n",
    "\n",
    "sns.pairplot(sub_train_data, height=3.5, plot_kws={\"alpha\": 0.4})\n",
    "plt.tight_layout()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Build up a linear regressor & a decision tree regressor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Linear regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "# Import library for linear regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Training\n",
    "# Create a Linear regressor\n",
    "linear_regressor = LinearRegression()\n",
    "\n",
    "# Train the model using the training sets\n",
    "linear_regressor.fit(X_train, y_train)\n",
    "\n",
    "# Display the learned parameters\n",
    "# Convert the coefficient values to a dataframe\n",
    "coeffcients = pd.DataFrame(\n",
    "    linear_regressor.coef_, X_train.columns, columns=[\"Coefficient\"]\n",
    ")\n",
    "\n",
    "# Display the intercept value\n",
    "print(\"Learned intercept: {:.2f}\".format(linear_regressor.intercept_))\n",
    "\n",
    "print(\"\\n--The learned coefficient value learned by the linear regression model--\")\n",
    "print(coeffcients)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Import the built-in MSE metric\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Model prediction on training data\n",
    "y_pred_train = linear_regressor.predict(X_train)\n",
    "print(\"\\n--Train MSE--\\n{}\".format(mean_squared_error(y_train, y_pred_train)))\n",
    "\n",
    "\n",
    "# Testing\n",
    "y_pred_test = linear_regressor.predict(X_test)\n",
    "\n",
    "print(\"Test MSE: {:.2f}\".format(mean_squared_error(y_test, y_pred_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "# Visualizing the differences between actual prices and predicted values\n",
    "plt.scatter(y_test, y_pred_test)\n",
    "plt.xlabel(\"MedPrice\")\n",
    "plt.ylabel(\"Predicted MedPrice\")\n",
    "plt.title(\"MedPrice vs Predicted MedPrice\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "# Checking Normality of errors\n",
    "sns.distplot(y_test - y_pred_test)\n",
    "plt.title(\"Histogram of Residuals\")\n",
    "plt.xlabel(\"Residuals\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Decision tree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "# Import library for decision tree\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "tree_regressor = DecisionTreeRegressor(max_depth=3, random_state=42)\n",
    "tree_regressor.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "# Model prediction on training & test data\n",
    "y_pred_train = tree_regressor.predict(X_train)\n",
    "y_pred_test = tree_regressor.predict(X_test)\n",
    "\n",
    "print(\"Train MSE: {:.2f}\".format(mean_squared_error(y_train, y_pred_train)))\n",
    "\n",
    "print(\"Test MSE: {:.2f}\".format(mean_squared_error(y_test, y_pred_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "# Plot outputs\n",
    "# Visualizing the differences between actual prices and predicted values\n",
    "plt.scatter(y_test, y_pred_test)\n",
    "plt.xlabel(\"MedPrice\")\n",
    "plt.ylabel(\"Predicted MedPrice\")\n",
    "plt.title(\"MedPrice vs Predicted MedPrice\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "# Visualizing the decision tree\n",
    "from six import StringIO\n",
    "import sklearn.tree as tree\n",
    "import pydotplus\n",
    "\n",
    "from IPython.display import Image\n",
    "\n",
    "dot_data = StringIO()\n",
    "tree.export_graphviz(\n",
    "    tree_regressor,\n",
    "    out_file=dot_data,\n",
    "    class_names=[\"MedPrice\"],  # the target names.\n",
    "    feature_names=selected_feature_set,  # the feature names.\n",
    "    filled=True,  # Whether to fill in the boxes with colours.\n",
    "    rounded=True,  # Whether to round the corners of the boxes.\n",
    "    special_characters=True,\n",
    ")\n",
    "graph = pydotplus.graph_from_dot_data(dot_data.getvalue())\n",
    "Image(graph.create_png())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Fine-Tuning: tune the tree depth hyperparameter in the tree regressor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "kf = KFold(n_splits=5)  # sample indices of datasets for 5-fold cv\n",
    "\n",
    "cv_sets = []\n",
    "for train_index, test_index in kf.split(X_train):\n",
    "    cv_sets.append(\n",
    "        (\n",
    "            X_train.iloc[train_index],\n",
    "            y_train.iloc[train_index],\n",
    "            X_train.iloc[test_index],\n",
    "            y_train.iloc[test_index],\n",
    "        )\n",
    "    )  # construct 5-fold cv datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "max_depths = list(range(1, 11))  # candidate max_depth hyperparamters\n",
    "\n",
    "for max_depth in max_depths:\n",
    "    cv_results = []\n",
    "    regressor = DecisionTreeRegressor(max_depth=max_depth, random_state=42)\n",
    "for (\n",
    "    x_tr,\n",
    "    y_tr,\n",
    "    x_te,\n",
    "    y_te,\n",
    ") in cv_sets:  # loop through all the cv sets and average the validation results\n",
    "    regressor.fit(x_tr, y_tr)\n",
    "    cv_results.append(mean_squared_error(regressor.predict(x_te), y_te))\n",
    "print(\"Tree depth: {}, Avg. MSE: {}\".format(max_depth, np.mean(cv_results)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "# Hp tuning with Sklearn\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "# Build up the decision tree regressor\n",
    "regressor = DecisionTreeRegressor(random_state=42)\n",
    "\n",
    "# Create a dictionary for the hyperparameter 'max_depth' with a range from 1 to 10\n",
    "hps = {\"max_depth\": list(range(1, 11))}\n",
    "\n",
    "# Transform 'performance_metric' into a scoring function using 'make_scorer'.\n",
    "# The default scorer function is the greater the better, here MSE is the lower the better,\n",
    "# so we set ``greater_is_better'' to be False.\n",
    "scoring_fnc = make_scorer(mean_squared_error, greater_is_better=False)\n",
    "\n",
    "# Create the grid search cv object (5-fold cross-validation)\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=regressor, param_grid=hps, scoring=scoring_fnc, cv=5\n",
    ")\n",
    "\n",
    "# Fit the grid search object to the training data to search the optimal model\n",
    "grid_search = grid_search.fit(X_train, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "cvres = grid_search.cv_results_\n",
    "for mean_score, params in zip(cvres[\"mean_test_score\"], cvres[\"params\"]):\n",
    "    print(-mean_score, params)\n",
    "\n",
    "plt.plot(hps[\"max_depth\"], -cvres[\"mean_test_score\"])\n",
    "plt.title(\"5-fold CV MSE change with tree max depth\")\n",
    "plt.xlabel(\"max_depth\")\n",
    "plt.ylabel(\"MSE\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Retrive the best model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "grid_search.best_params_\n",
    "best_tree_regressor = grid_search.best_estimator_\n",
    "\n",
    "# Produce the value for 'max_depth'\n",
    "print(\"Best hyperparameter is {}.\".format(grid_search.best_params_))\n",
    "\n",
    "# Model prediction on training & test data\n",
    "y_pred_train = best_tree_regressor.predict(X_train)\n",
    "y_pred_test = best_tree_regressor.predict(X_test)\n",
    "\n",
    "print(\"\\n--Train MSE--\\n{}\".format(mean_squared_error(y_train, y_pred_train)))\n",
    "\n",
    "print(\"\\n--Test MSE--\\n{}\\n\".format(mean_squared_error(y_test, y_pred_test)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Real test curve V.S. cross-validation curve\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "test_results = []\n",
    "for max_depth in hps[\"max_depth\"]:\n",
    "    tmp_results = []\n",
    "    regressor = DecisionTreeRegressor(max_depth=max_depth, random_state=42)\n",
    "    regressor.fit(X_train, y_train)\n",
    "    test_results.append(mean_squared_error(regressor.predict(X_test), y_test))\n",
    "    print(\"Tree depth: {}, Test MSE: {}\".format(max_depth, test_results[-1]))\n",
    "\n",
    "plt.plot(hps[\"max_depth\"], -cvres[\"mean_test_score\"])\n",
    "plt.plot(hps[\"max_depth\"], test_results)\n",
    "plt.title(\"Comparison of the changing curve of the CV results and real test results\")\n",
    "plt.legend([\"CV\", \"Test\"])\n",
    "plt.xlabel(\"max_depth\")\n",
    "plt.ylabel(\"MSE\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "2.2-House-Price-Prediction",
   "private_outputs": false,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}